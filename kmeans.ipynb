{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d53c826-c77d-4775-9a36-f0ea72fa6e89",
   "metadata": {},
   "source": [
    "# K-means: Intra-cluster Minimization\n",
    "\n",
    "We consider a set of points\n",
    "\n",
    "$$\n",
    "x_1, \\dots, x_n \\in \\mathbb{R}^d\n",
    "$$\n",
    "\n",
    "which are partitioned into $k$ clusters $C_1, \\dots, C_k$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf560d-0a14-4272-9666-c6c0e58abfb2",
   "metadata": {},
   "source": [
    "## Optimization Problem\n",
    "\n",
    "The K-means objective function is\n",
    "\n",
    "$$\n",
    "J(C, \\mu) = \\sum_{j=1}^k \\sum_{i \\in C_j} \\|x_i - \\mu_j\\|^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $C_j$ is the $j$-th cluster,\n",
    "- $\\mu_j \\in \\mathbb{R}^d$ is the center of the cluster.\n",
    "\n",
    "We aim to minimize $J(C,\\mu)$ with respect to $C$ and $\\mu$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b9252-35b3-4f91-ba49-cd0c1f30e19f",
   "metadata": {},
   "source": [
    "## Theorem\n",
    "\n",
    "If the partition $C_j$ is fixed, then the minimizer of\n",
    "$$\n",
    "\\sum_{i \\in C_j} \\|x_i - \\mu\\|^2\n",
    "$$\n",
    "\n",
    "***We, therefore are in a situation where Kmeans is in fact convexe However, it is convex in clusters not overall***\n",
    "\n",
    "is given by the empirical mean(estimator)\n",
    "\n",
    "$$\n",
    "\\mu_j^\\star = \\frac{1}{|C_j|} \\sum_{i \\in C_j} x_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af76987-9e44-49e6-b9bc-47a6d0fdec9b",
   "metadata": {},
   "source": [
    "## Proof\n",
    "\n",
    "Fix a cluster $C_j$ and consider the function\n",
    "\n",
    "$$\n",
    "\\phi(\\mu) = \\sum_{i \\in C_j} \\|x_i - \\mu\\|^2\n",
    "$$\n",
    "\n",
    "We expand each squared norm\n",
    "\n",
    "$$\n",
    "\\|x_i - \\mu\\|^2\n",
    "= (x_i - \\mu)^T (x_i - \\mu)\n",
    "= x_i^T x_i - 2 x_i^T \\mu + \\mu^T \\mu\n",
    "$$\n",
    "\n",
    "Summing over all $i \\in C_j$, we obtain\n",
    "\n",
    "$$\n",
    "\\phi(\\mu)\n",
    "= \\sum_{i \\in C_j} x_i^T x_i\n",
    "- 2 \\sum_{i \\in C_j} x_i^T \\mu\n",
    "+ |C_j| \\mu^T \\mu\n",
    "$$\n",
    "\n",
    "We compute the gradient with respect to $\\mu$\n",
    "\n",
    "$$\n",
    "\\nabla_\\mu \\phi(\\mu)\n",
    "= -2 \\sum_{i \\in C_j} x_i + 2 |C_j| \\mu\n",
    "$$\n",
    "\n",
    "Setting the gradient equal to zero\n",
    "\n",
    "$$\n",
    "-2 \\sum_{i \\in C_j} x_i + 2 |C_j| \\mu = 0\n",
    "$$\n",
    "\n",
    "This gives\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{1}{|C_j|} \\sum_{i \\in C_j} x_i\n",
    "$$\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "For each cluster, the center minimizing the intra-cluster sum of squared\n",
    "distances is the mean of the points assigned to the cluster.\n",
    "\n",
    "This result explains the update step of the K-means algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80242fcc-1b1c-44fc-87c6-bf3ebf0dc221",
   "metadata": {},
   "source": [
    "## Non-convexity of the global K-means objective\n",
    "\n",
    "Let $x_1,\\dots,x_n \\in \\mathbb{R}^d$ be a set of data points and let $k \\ge 2$.\n",
    "The global K-means objective function can be written as\n",
    "\n",
    "$$\n",
    "F(\\mu_1,\\dots,\\mu_k)\n",
    "=\n",
    "\\sum_{i=1}^n \\min_{j\\in\\{1,\\dots,k\\}} \\|x_i-\\mu_j\\|^2.\n",
    "$$\n",
    "\n",
    "This formulation reflects the fact that each data point is assigned to the\n",
    "closest cluster center.\n",
    "\n",
    "---\n",
    "\n",
    "### Definition of convexity\n",
    "\n",
    "A function $F$ is convex if for all $u,v$ in its domain and for all\n",
    "$\\lambda \\in [0,1]$, it satisfies\n",
    "\n",
    "$$\n",
    "F(\\lambda u + (1-\\lambda)v)\n",
    "\\le\n",
    "\\lambda F(u) + (1-\\lambda)F(v).\n",
    "$$\n",
    "\n",
    "To show that $F$ is not convex, it is sufficient and quite easy to demonstrate it with a counterexample\n",
    "for which this inequality does not hold.\n",
    "\n",
    "---\n",
    "\n",
    "### Counterexample\n",
    "\n",
    "We consider the simplest non-trivial case:\n",
    "- dimension $d=1$,\n",
    "- one data point $n=1$,\n",
    "- two clusters $k=2$,\n",
    "- data point $x_1 = 0$.\n",
    "\n",
    "In this case, the objective function reduces to\n",
    "\n",
    "$$\n",
    "F(\\mu_1,\\mu_2) = \\min(\\mu_1^2,\\mu_2^2).\n",
    "$$\n",
    "\n",
    "Let us choose two sets of centers\n",
    "\n",
    "$$\n",
    "u = (1,0),\n",
    "\\qquad\n",
    "v = (0,1).\n",
    "$$\n",
    "\n",
    "We compute\n",
    "\n",
    "$$\n",
    "F(u) = \\min(1,0) = 0,\n",
    "\\qquad\n",
    "F(v) = \\min(0,1) = 0.\n",
    "$$\n",
    "\n",
    "Now take $\\lambda = \\frac{1}{2}$.\n",
    "The midpoint between $u$ and $v$ is\n",
    "\n",
    "$$\n",
    "\\frac{u+v}{2} = (0.5,0.5).\n",
    "$$\n",
    "\n",
    "Evaluating the objective function at this point yields\n",
    "\n",
    "$$\n",
    "F\\left(\\frac{u+v}{2}\\right)\n",
    "=\n",
    "\\min(0.25,0.25)\n",
    "=\n",
    "0.25.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Violation of the convexity inequality\n",
    "\n",
    "If $F$ were convex, we would have\n",
    "\n",
    "$$\n",
    "F\\left(\\frac{u+v}{2}\\right)\n",
    "\\le\n",
    "\\frac{F(u)+F(v)}{2}.\n",
    "$$\n",
    "\n",
    "However,\n",
    "\n",
    "$$\n",
    "\\frac{F(u)+F(v)}{2} = 0,\n",
    "$$\n",
    "\n",
    "while\n",
    "\n",
    "$$\n",
    "F\\left(\\frac{u+v}{2}\\right) = 0.25 > 0.\n",
    "$$\n",
    "\n",
    "This contradicts the convexity inequality.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The convexity inequality is violated for the global K-means objective function.\n",
    "Therefore, the K-means objective is not convex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d7b88-ae0b-4216-9255-8101300db6fa",
   "metadata": {},
   "source": [
    "***Starting Kmeans implementation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fab8871-56db-4b30-89e0-aa865c9b8524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199e8544-565a-42ce-91d2-9d18f9ff2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "vers = {\n",
    "    \"numpy\" : np.__version__,\n",
    "    \"python\" : sys.version_info[:3],\n",
    "    \"matplot\" : tuple(map(int,matplotlib.__version__.split(\".\")[:3]))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33b0f048-ed27-44fb-a226-6d74222273aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_vers(d : dict):\n",
    "    if isinstance(d,dict):\n",
    "        for name,val in vers.items():\n",
    "            if name == \"python\":\n",
    "                if val > (3,10):\n",
    "                    print(f\"Python sys info correct {val} \\n\")\n",
    "            else:\n",
    "                print(f\"Version of {name}:{val}\\n\")\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f0e1d1c-0b55-4170-a814-659a9149f9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.rand(5,6)\n",
    "B = np.random.rand(5,6)\n",
    "\n",
    "X = np.c_[A.ravel(),B.ravel()]\n",
    "X.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682cb90-ffa9-4e29-b569-2ea527e3a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def timer(func):\n",
    "    def wrapper(*args,**kwargs):\n",
    "        deb = time.time()\n",
    "        f = func(*args,**kwargs)\n",
    "        end = time.time()\n",
    "        res = end-deb\n",
    "        return \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bd36607-f283-4d2f-9bb3-dc11de41bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMEANS:\n",
    "    def __init__(self,k,max_iter=10):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "        self.inertia = None\n",
    "\n",
    "    def fit(self,X):\n",
    "        X = np.asarray(X)\n",
    "        sampl = X.shape[0]\n",
    "        #I select k random values amongst all\n",
    "        self.centroids = X[np.random.choice(sampl,k,replace=False)]\n",
    "        for _ in range(self.max_iter):\n",
    "            self.labels = cluster_assign(X,self.centroids)\n",
    "            assert self.labels.shape[0] == sampl\n",
    "            assert np.all((self.labels >= 0) & (self.labels < self.k)) #check if true and \n",
    "            NEW_Centroids = centroids_update(X,self.labels,self.k)\n",
    "            if np.allclose(self.centroids,NEW_Centroids):#to check if the centroids evolved\n",
    "                break\n",
    "            self.centroids = NEW_Centroids\n",
    "        return self\n",
    "            \n",
    "    def predict(self,X):\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        if self.centroids is None:\n",
    "            raise ValueError(\"An error occured, model not fitted\")\n",
    "        return cluster_assign(X,self.centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b5f1c77-dbc4-4754-ac50-08fc852bfeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fairly simple Euclidianj distance function, using dot product to optimize\n",
    "\"\"\"\n",
    "def Euclid_Distance(x : np.ndarray, mu : np.ndarray) -> float:\n",
    "    x = np.asarray(x)\n",
    "    mu = np.asarray(mu)\n",
    "    assert x.ndim == 1\n",
    "    assert mu.ndim == 1\n",
    "    assert x.shape == mu.shape\n",
    "    return np.dot(x-mu,x-mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47ff037b-c261-4ad7-8638-9d358c614c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0.0, 0.0])\n",
    "mu = np.array([1.0, 0.0])\n",
    "Euclid_Distance(x, mu)  # doit donner 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b88e55ce-8a60-415d-8560-5129eccd5fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple assignation function, where we check for each variable x(observation) and cs(centroids)\n",
    "calculate the distance between the observation and each cluster's centroid then return the min\n",
    "the min shall be used later for the cluster assigning function that shall assign an observation to a cluster\n",
    "\"\"\"\n",
    "\n",
    "def assignation(x: np.ndarray, centroids: np.ndarray):\n",
    "    x = np.asarray(x)\n",
    "    centroids = np.asarray(centroids)\n",
    "\n",
    "    assert centroids.ndim == 2\n",
    "    assert x.ndim == 1\n",
    "\n",
    "    DIST = np.empty(len(centroids))\n",
    "\n",
    "    for j in range(len(centroids)):\n",
    "        DIST[j] = Euclid_Distance(x, centroids[j])\n",
    "\n",
    "    return np.argmin(DIST)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e60ff99-43e1-4b17-b694-592372d87bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Quite simple function, assign an observation xi to a centroid by minimizing the distance between obs and centroid see maths up above\n",
    "\"\"\"\n",
    "\n",
    "def cluster_assign(X, centroids):\n",
    "    X = np.asarray(X)\n",
    "    centroids = np.asarray(centroids)\n",
    "\n",
    "    labels = np.empty(X.shape[0], dtype=int)\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        labels[i] = assignation(X[i], centroids)\n",
    "        \n",
    "    return labels\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc789a4c-f203-403f-a5e9-7de6164ecb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For k cluster, I create accumulators + sums and for a label label[i] I retrieve it and add to the appropriate accumulator the value of X\n",
    "then I calculate the means of my new centroids\n",
    "\"\"\"\n",
    "\n",
    "def centroids_update(X,labels,k):\n",
    "    X = np.asarray(X)\n",
    "    size1,size2 = X.shape\n",
    "    accum = np.zeros(k,dtype=int)\n",
    "    sam = np.zeros((k,size2))\n",
    "   \n",
    "    for i in range(len(labels)):\n",
    "        c = labels[i]\n",
    "        sam[c] += X[i]\n",
    "        accum[c] += 1\n",
    "\n",
    "    centroids = np.zeros((k,size2))\n",
    "\n",
    "    for c in range(k):\n",
    "        if accum[c] > 0:\n",
    "            centroids[c] = sam[c]/accum[c]\n",
    "        else:\n",
    "            raise ValueError(\"there are less possible label value than clusters\")\n",
    "    return centroids\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4088bc6-88af-4c02-9062-ebb1534c12c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
